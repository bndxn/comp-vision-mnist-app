{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "x : tensor([[[0.6196, 0.6235, 0.6471,  ..., 0.5373, 0.4941, 0.4549],\n",
      "         [0.5961, 0.5922, 0.6235,  ..., 0.5333, 0.4902, 0.4667],\n",
      "         [0.5922, 0.5922, 0.6196,  ..., 0.5451, 0.5098, 0.4706],\n",
      "         ...,\n",
      "         [0.2667, 0.1647, 0.1216,  ..., 0.1490, 0.0510, 0.1569],\n",
      "         [0.2392, 0.1922, 0.1373,  ..., 0.1020, 0.1137, 0.0784],\n",
      "         [0.2118, 0.2196, 0.1765,  ..., 0.0941, 0.1333, 0.0824]],\n",
      "\n",
      "        [[0.4392, 0.4353, 0.4549,  ..., 0.3725, 0.3569, 0.3333],\n",
      "         [0.4392, 0.4314, 0.4471,  ..., 0.3725, 0.3569, 0.3451],\n",
      "         [0.4314, 0.4275, 0.4353,  ..., 0.3843, 0.3725, 0.3490],\n",
      "         ...,\n",
      "         [0.4863, 0.3922, 0.3451,  ..., 0.3804, 0.2510, 0.3333],\n",
      "         [0.4549, 0.4000, 0.3333,  ..., 0.3216, 0.3216, 0.2510],\n",
      "         [0.4196, 0.4118, 0.3490,  ..., 0.3020, 0.3294, 0.2627]],\n",
      "\n",
      "        [[0.1922, 0.1843, 0.2000,  ..., 0.1412, 0.1412, 0.1294],\n",
      "         [0.2000, 0.1569, 0.1765,  ..., 0.1216, 0.1255, 0.1333],\n",
      "         [0.1843, 0.1294, 0.1412,  ..., 0.1333, 0.1333, 0.1294],\n",
      "         ...,\n",
      "         [0.6941, 0.5804, 0.5373,  ..., 0.5725, 0.4235, 0.4980],\n",
      "         [0.6588, 0.5804, 0.5176,  ..., 0.5098, 0.4941, 0.4196],\n",
      "         [0.6275, 0.5843, 0.5176,  ..., 0.4863, 0.5059, 0.4314]]]), y: 1\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 3, 32, 32])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# From here https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Download training data from open datasets.\n",
    "train_dataset = datasets.CIFAR10(\n",
    "    train=True,\n",
    "    root=\"data\",\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    train=False,\n",
    "    root=\"data\",\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "class TwoClassDataset(Dataset):\n",
    "    def __init__(self, original_dataset, class_indices, transform=None):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.class_indices = class_indices\n",
    "        self.filtered_indices = self._filter_indices()\n",
    "\n",
    "    def _filter_indices(self):\n",
    "        # Filter indices based on selected classes\n",
    "        return [idx for idx in range(len(self.original_dataset)) if self.original_dataset[idx][1] in self.class_indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filtered_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the item from the original dataset using filtered indices\n",
    "        original_idx = self.filtered_indices[idx]\n",
    "        sample, target = self.original_dataset[original_idx]\n",
    "\n",
    "        # Map the original class indices to new indices\n",
    "        target = self.class_indices.index(target)\n",
    "        return sample, target\n",
    "\n",
    "selected_classes = [1, 3]  \n",
    "\n",
    "# Create a new dataset with only the selected classes\n",
    "train_data = TwoClassDataset(train_dataset, selected_classes)\n",
    "\n",
    "# change this to be a validation set, taken from the training, with test only used at the end\n",
    "test_data = TwoClassDataset(test_dataset, selected_classes)\n",
    "\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "print(f\"x : {x}, y: {y}\")\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 1\n",
      "---------------------\n",
      "batch number: 0, loss: 2.317953 [   64/10000]\n",
      "batch number: 100, loss: 1.544761 [ 6464/10000]\n",
      "Test Error: \n",
      "Accuracy: 58.8, Avg loss: 1.039388 \n",
      "\n",
      "Epoch 2\n",
      "---------------------\n",
      "batch number: 0, loss: 1.029235 [   64/10000]\n",
      "batch number: 100, loss: 0.805737 [ 6464/10000]\n",
      "Test Error: \n",
      "Accuracy: 70.7, Avg loss: 0.748107 \n",
      "\n",
      "Epoch 3\n",
      "---------------------\n",
      "batch number: 0, loss: 0.748445 [   64/10000]\n",
      "batch number: 100, loss: 0.725353 [ 6464/10000]\n",
      "Test Error: \n",
      "Accuracy: 72.3, Avg loss: 0.699400 \n",
      "\n",
      "Epoch 4\n",
      "---------------------\n",
      "batch number: 0, loss: 0.704363 [   64/10000]\n",
      "batch number: 100, loss: 0.696124 [ 6464/10000]\n",
      "Test Error: \n",
      "Accuracy: 72.5, Avg loss: 0.674996 \n",
      "\n",
      "Epoch 5\n",
      "---------------------\n",
      "batch number: 0, loss: 0.683014 [   64/10000]\n",
      "batch number: 100, loss: 0.676826 [ 6464/10000]\n",
      "Test Error: \n",
      "Accuracy: 72.4, Avg loss: 0.656184 \n",
      "\n",
      "Epoch 6\n",
      "---------------------\n",
      "batch number: 0, loss: 0.667061 [   64/10000]\n",
      "batch number: 100, loss: 0.660384 [ 6464/10000]\n",
      "Test Error: \n",
      "Accuracy: 72.9, Avg loss: 0.638678 \n",
      "\n",
      "Epoch 7\n",
      "---------------------\n",
      "batch number: 0, loss: 0.652443 [   64/10000]\n",
      "batch number: 100, loss: 0.644836 [ 6464/10000]\n",
      "Test Error: \n",
      "Accuracy: 72.9, Avg loss: 0.621655 \n",
      "\n",
      "Epoch 8\n",
      "---------------------\n",
      "batch number: 0, loss: 0.638290 [   64/10000]\n",
      "batch number: 100, loss: 0.630336 [ 6464/10000]\n",
      "Test Error: \n",
      "Accuracy: 73.5, Avg loss: 0.605365 \n",
      "\n",
      "Epoch 9\n",
      "---------------------\n",
      "batch number: 0, loss: 0.625095 [   64/10000]\n",
      "batch number: 100, loss: 0.617138 [ 6464/10000]\n",
      "Test Error: \n",
      "Accuracy: 73.7, Avg loss: 0.589923 \n",
      "\n",
      "Epoch 10\n",
      "---------------------\n",
      "batch number: 0, loss: 0.613007 [   64/10000]\n",
      "batch number: 100, loss: 0.605356 [ 6464/10000]\n",
      "Test Error: \n",
      "Accuracy: 73.9, Avg loss: 0.575483 \n",
      "\n",
      "Epoch 11\n",
      "---------------------\n",
      "batch number: 0, loss: 0.602253 [   64/10000]\n",
      "batch number: 100, loss: 0.594765 [ 6464/10000]\n",
      "Test Error: \n",
      "Accuracy: 74.2, Avg loss: 0.562214 \n",
      "\n",
      "Epoch 12\n",
      "---------------------\n",
      "batch number: 0, loss: 0.593047 [   64/10000]\n",
      "batch number: 100, loss: 0.585351 [ 6464/10000]\n",
      "Test Error: \n",
      "Accuracy: 74.7, Avg loss: 0.550473 \n",
      "\n",
      "Epoch 13\n",
      "---------------------\n",
      "batch number: 0, loss: 0.585286 [   64/10000]\n",
      "batch number: 100, loss: 0.576827 [ 6464/10000]\n",
      "Test Error: \n",
      "Accuracy: 75.3, Avg loss: 0.539953 \n",
      "\n",
      "Epoch 14\n",
      "---------------------\n",
      "batch number: 0, loss: 0.578829 [   64/10000]\n",
      "batch number: 100, loss: 0.569066 [ 6464/10000]\n",
      "Test Error: \n",
      "Accuracy: 75.9, Avg loss: 0.530561 \n",
      "\n",
      "Epoch 15\n",
      "---------------------\n",
      "batch number: 0, loss: 0.573455 [   64/10000]\n",
      "batch number: 100, loss: 0.561962 [ 6464/10000]\n",
      "Test Error: \n",
      "Accuracy: 76.4, Avg loss: 0.522175 \n",
      "\n",
      "Epoch 16\n",
      "---------------------\n",
      "batch number: 0, loss: 0.568923 [   64/10000]\n",
      "batch number: 100, loss: 0.555451 [ 6464/10000]\n",
      "Test Error: \n",
      "Accuracy: 77.2, Avg loss: 0.514701 \n",
      "\n",
      "Epoch 17\n",
      "---------------------\n",
      "batch number: 0, loss: 0.565119 [   64/10000]\n",
      "batch number: 100, loss: 0.549428 [ 6464/10000]\n",
      "Test Error: \n",
      "Accuracy: 77.4, Avg loss: 0.508052 \n",
      "\n",
      "Epoch 18\n",
      "---------------------\n",
      "batch number: 0, loss: 0.561883 [   64/10000]\n",
      "batch number: 100, loss: 0.543924 [ 6464/10000]\n",
      "Test Error: \n",
      "Accuracy: 77.6, Avg loss: 0.502150 \n",
      "\n",
      "Epoch 19\n",
      "---------------------\n",
      "batch number: 0, loss: 0.559139 [   64/10000]\n",
      "batch number: 100, loss: 0.538736 [ 6464/10000]\n",
      "Test Error: \n",
      "Accuracy: 78.0, Avg loss: 0.496917 \n",
      "\n",
      "Epoch 20\n",
      "---------------------\n",
      "batch number: 0, loss: 0.556733 [   64/10000]\n",
      "batch number: 100, loss: 0.533941 [ 6464/10000]\n",
      "Test Error: \n",
      "Accuracy: 78.3, Avg loss: 0.492265 \n",
      "\n",
      "Done!\n",
      "Train losses [1.9313572645187378, 0.917485922574997, 0.7368993163108826, 0.7002438008785248, 0.6799198389053345, 0.6637223660945892, 0.6486396491527557, 0.6343131363391876, 0.6211168766021729, 0.6091816127300262, 0.5985088348388672, 0.5891989767551422, 0.5810560286045074, 0.5739476084709167, 0.5677085518836975, 0.5621872544288635, 0.5572734177112579, 0.5529033541679382, 0.5489372611045837, 0.545336902141571]\n",
      "Test losses [1.0393882226198912, 0.748107248917222, 0.6994002796709538, 0.6749956868588924, 0.6561844442039728, 0.6386780980974436, 0.6216546706855297, 0.6053651086986065, 0.5899228025227785, 0.5754825789481401, 0.5622136723250151, 0.5504725137725472, 0.5399528471753001, 0.5305613558739424, 0.5221753213554621, 0.5147011848166585, 0.5080517735332251, 0.5021503232419491, 0.49691701121628284, 0.4922649608924985]\n",
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define model\n",
    "# nn.Module is the Base class for all neural network modules\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(3*32*32, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "\n",
    "# To train the model we need a loss function and an optimizer\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "# Invoke lists for the accuracy and loss values at the end of each epoch\n",
    "train_losses, train_accuracies = [], []\n",
    "test_losses, test_accuracies = [], []\n",
    "\n",
    "# We define training including the predictions and backpropagations\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    epoch_losses, epoch_accuracies = [], []\n",
    "    size = len(dataloader.dataset) # why do we need this? \n",
    "    model.train() # sets the module in training mode\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Use the loss function to update the weights \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0: # % is remainder \n",
    "        # this prints a result every 100 items \n",
    "            batch_loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"batch number: {batch}, loss: {batch_loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "            epoch_losses.append(batch_loss)\n",
    "    \n",
    "    epoch_loss = np.array(epoch_losses).mean()\n",
    "    train_losses.append(epoch_loss)\n",
    "\n",
    "def test(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0 \n",
    "    with torch.no_grad(): # context manager that disables gradient calculation\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    test_losses.append(test_loss)\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\nAccuracy: {(100*correct):>0.1f}, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "# Conduct training over several epochs\n",
    "if __name__ == '__main__':\n",
    "    epochs = 20\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n---------------------\")\n",
    "        train(train_dataloader, model, loss_fn, optimizer)\n",
    "        test(test_dataloader, model, loss_fn, optimizer)\n",
    "    print(\"Done!\")\n",
    "    print('Train losses', train_losses)\n",
    "    print('Test losses', test_losses)\n",
    "\n",
    "\n",
    "    torch.save(model.state_dict(), \"model.pth\")\n",
    "    print(\"Saved PyTorch Model State to model.pth\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6982e0fe80>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(211)\n",
    "plt.plot(train_losses, 'bo', label='Training loss')\n",
    "plt.plot(test_losses, 'r', label='Validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
